{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e12b95-eaff-4a21-93e9-92c6fdf3cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, sys, time, os, math, tqdm, numpy, soundfile, time, pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from model.layers import TacotronSTFT\n",
    "from model.ast_model import ASTModel\n",
    "from model.wavenet import WaveNet\n",
    "from model.JCU_MSD import JCU_MSD\n",
    "from model.losses import DAMSoftmax, PredictionLoss, generator_loss, \\\n",
    "                         discriminator_loss, get_mel_loss, get_fm_loss\n",
    "\n",
    "from Dataset.dataset import Fbank_DataLoader\n",
    "from scipy.io.wavfile import read\n",
    "\n",
    "from tools import *\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c7522c2-e19a-4916-bdb6-8e6c7df28311",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Fbank_DataLoader('Dataset/filelist_Vox1.txt')  #Batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337fea6d-9b5b-4bec-b798-bb7219f20cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2704"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b5f21a-0859-4ae1-932d-997d0a14cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359e6f40-961d-410b-9919-bf627d58b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASVframework(nn.Module):\n",
    "    def __init__(self,            \n",
    "                 input_tdim = 500, \n",
    "                 emb_dim = 768,\n",
    "                 class_nums = 1299,\n",
    "                 hidden_nums = 256\n",
    "                ):\n",
    "        \n",
    "        super(ASVframework, self).__init__()\n",
    "        # optim \n",
    "        self.grad_acc_step = 1\n",
    "        self.grad_clip_thresh = 1\n",
    "        \n",
    "        # FT\n",
    "        self.target_lenght = input_tdim\n",
    "        self.stft = TacotronSTFT(filter_length=1024,\n",
    "                                 hop_length=256,\n",
    "                                 win_length=1024,\n",
    "                                 sampling_rate=22050,\n",
    "                                 mel_fmin=0, mel_fmax=8000)      \n",
    "        \n",
    "        # ASV   \n",
    "        self.encoder = ASTModel(label_dim=1, fshape=128, tshape=2, fstride=128, tstride=1,\n",
    "                       input_fdim=128, input_tdim=input_tdim, model_size='base',\n",
    "                       pretrain_stage=False, load_pretrained_mdl_path='save_model/SSAST-Base-Frame-400.pth').cuda()\n",
    "        self.closs = DAMSoftmax(emb_dim, class_nums).cuda() \n",
    "        self.ploss = PredictionLoss(emb_dim, hidden_nums).cuda() \n",
    "        self.asv_opt  = torch.optim.Adam([{'params': self.encoder.parameters()},\n",
    "                                          # {'params': self.closs.parameters()},\n",
    "                                          # {'params': self.ploss.parameters()},\n",
    "                                          ], \n",
    "                                          lr=1e-4, \n",
    "                                          betas=(0.95, 0.99), weight_decay = 2e-5)\n",
    "   \n",
    "        self.ft_opt = torch.optim.Adam(self.ploss.parameters(), lr=1e-4, \n",
    "                                       betas=(0.9, 0.99), weight_decay = 2e-5)\n",
    "        # self.ft_opt = torch.optim.Adam([{'params': self.encoder.parameters(),'lr': 1e-3},\n",
    "        #                                 {'params': self.ploss.parameters()}], lr=1e-4, \n",
    "        #                                 betas=(0.9, 0.99), weight_decay = 2e-5)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.StepLR(self.optim, step_size = test_step, gamma=lr_decay)\n",
    "        \n",
    "        # FRN \n",
    "        # self.gen = WaveNet(gin_channels=1, upsample_conditional_features=True).cuda()\n",
    "        # self.JCUMSD = JCU_MSD().cuda()\n",
    "        # self.genloss = generator_loss\n",
    "        # self.disloss = discriminator_loss\n",
    "        # self.specloss = get_mel_loss\n",
    "        # self.fmloss = get_fm_loss\n",
    "        # self.g_opt = torch.optim.Adam(self.gen.parameters(), lr=1e-4, \n",
    "        #                               betas=(0.9, 0.99), weight_decay = 2e-5)\n",
    "        # self.d_opt = torch.optim.Adam(self.JCUMSD.parameters(), lr=1e-3, \n",
    "        #                               betas=(0.9, 0.99), weight_decay = 2e-5) \n",
    "\n",
    "    def load_wav_to_torch(self, full_path):\n",
    "        \"\"\"\n",
    "        Loads wavdata into torch array\n",
    "        \"\"\"\n",
    "        sampling_rate, data = read(full_path)\n",
    "        return torch.from_numpy(data).float(), sampling_rate\n",
    "\n",
    "    def get_mel(self, audio):\n",
    "        audio_norm = audio / 32768.0\n",
    "        audio_norm = audio_norm.unsqueeze(0)\n",
    "        audio_norm = torch.autograd.Variable(audio_norm, requires_grad=False)\n",
    "        melspec = self.stft.mel_spectrogram(audio_norm)\n",
    "        melspec = torch.squeeze(melspec, 0).T\n",
    "        '''\n",
    "         mel = (D, T)\n",
    "        '''\n",
    "        #cut and pad\n",
    "        n_frames = melspec.shape[0]\n",
    "        p = self.target_lenght - n_frames\n",
    "        if p > 0:\n",
    "            m = torch.nn.ZeroPad2d((0, 0, 0, p))\n",
    "            melspec = m(melspec)\n",
    "        elif p < 0:\n",
    "            melspec = melspec[0:self.target_lenght, :]       \n",
    "            \n",
    "        return melspec\n",
    "     \n",
    "        \n",
    "    def model_update(self, model, step, loss, optimizer):\n",
    "        # Backward\n",
    "        loss = (loss / self.grad_acc_step).backward()\n",
    "        if step % self.grad_acc_step == 0:\n",
    "            # Clipping gradients to avoid gradient explosion\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), self.grad_clip_thresh)\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "\n",
    "    def save_parameters(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        \n",
    "    def load_parameters(self, path):\n",
    "        self_state = self.state_dict()\n",
    "        loaded_state = torch.load(path)\n",
    "        for name, param in loaded_state.items():\n",
    "            origname = name\n",
    "            if name not in self_state:\n",
    "                name = name.replace(\"module.\", \"\")\n",
    "                if name not in self_state:\n",
    "                    print(\"%s is not in the model.\"%origname)\n",
    "                    continue\n",
    "            if self_state[name].size() != loaded_state[origname].size():\n",
    "                print(\"Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state[origname].size()))\n",
    "                continue\n",
    "            self_state[name].copy_(param)   \n",
    "            \n",
    "            \n",
    "    def train_network(self, epoch, train_loader):\n",
    "        self.train()\n",
    "        \n",
    "        ## Update the learning rate based on the current epcoh\n",
    "        # self.scheduler.step(epoch - 1)\n",
    "        index, top1, top2, spk_loss, estimation_loss, \\\n",
    "        G_loss, D_loss = 0, 0, 0, 0, 0, 0, 0\n",
    "        lr = self.asv_opt.param_groups[0]['lr']        \n",
    "            \n",
    "        for i, (fbank_s, fbank_o, label, a) in enumerate(train_loader):\n",
    "            num = i+1\n",
    "            fbank_s = fbank_s.cuda()\n",
    "            fbank_o = fbank_o.cuda()\n",
    "            label   = label.cuda()\n",
    "            a       = a.unsqueeze(-1).cuda()\n",
    "            recon_a = torch.zeros_like(a).cuda()\n",
    "            \n",
    "            # train ASV system\n",
    "            self.asv_opt.zero_grad()\n",
    "            # fp16\n",
    "            with autocast():      \n",
    "                spk_emb = self.encoder(fbank_s, task='ft_emb')\n",
    "                cls_loss, acc = self.closs(spk_emb, a, label)           \n",
    "                # loss_asv_total = cls_loss + pred_loss      \n",
    "                \n",
    "            # optm ASV\n",
    "            scaler.scale(cls_loss).backward()\n",
    "            scaler.step(self.asv_opt)\n",
    "            scaler.update()\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "#             # optm prediction  \n",
    "#             self.ft_opt.zero_grad()\n",
    "#             with autocast(): \n",
    "#                 spk_emb = self.encoder(fbank_s, task='ft_emb')\n",
    "#                 cls_loss, acc, _ = self.closs(spk_emb, label)  \n",
    "#                 pred_loss, _     = self.ploss(spk_emb, a, label)\n",
    "#                 # loss_asv_total = cls_loss + pred_loss  \n",
    "            \n",
    "#             scaler.scale(pred_loss).backward()\n",
    "#             scaler.step(self.ft_opt)\n",
    "#             scaler.update()\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            # optm prediction  \n",
    "#             self.asv_opt.zero_grad()\n",
    "#             with autocast(): \n",
    "#                 spk_emb = self.encoder(fbank_s, task='ft_emb')\n",
    "#                 cls_loss , acc     = self.closs(spk_emb, label)  \n",
    "#                 pred_loss, acc2, _ = self.ploss(spk_emb, a)\n",
    "#                 loss_asv_total = 10*cls_loss + pred_loss  \n",
    "            \n",
    "#             scaler.scale(loss_asv_total).backward()\n",
    "#             scaler.step(self.asv_opt)\n",
    "#             scaler.update()\n",
    "    \n",
    "\n",
    "        \n",
    "#             # train FRN\n",
    "#             # train D\n",
    "#             fbank_recon = self.gen(fbank_s.transpose(2,1), g=-pred_a).transpose(2,1)\n",
    "#             D_real_cond, D_real_uncond = self.JCUMSD(fbank_o, fbank_s, label)\n",
    "#             D_fake_cond, D_fake_uncond = self.JCUMSD(fbank_recon.detach(), fbank_s, label)\n",
    "        \n",
    "#             loss_D = self.disloss(D_real_cond, D_real_uncond, D_fake_cond, D_fake_uncond)\n",
    "#             # optm JCU-MSD\n",
    "#             self.JCUMSD.zero_grad()\n",
    "#             loss_D.backward()\n",
    "#             self.d_opt.step()\n",
    "                \n",
    "#             # train G\n",
    "#             fbank_recon = self.gen(fbank_s.transpose(2,1), g=-pred_a).transpose(2,1)\n",
    "#             recon_emb = self.encoder(fbank_recon, task='ft_emb')\n",
    "#             # fool asv system\n",
    "#             loss_asv, _ = self.ploss(recon_emb, recon_a)\n",
    "        \n",
    "#             D_real_cond, D_real_uncond = self.JCUMSD(fbank_o, fbank_s, label)\n",
    "#             D_fake_cond, D_fake_uncond = self.JCUMSD(fbank_recon, fbank_s, label)\n",
    "\n",
    "#             loss_adv   = self.genloss(D_fake_cond, D_fake_uncond) \n",
    "#             loss_recon = self.specloss(fbank_recon, fbank_o)          \n",
    "#             loss_FM    = self.fmloss(D_real_cond, D_real_uncond, D_fake_cond, D_fake_uncond)\n",
    "#             lambda_FM  = loss_recon.item() / loss_FM.item()     \n",
    "#             loss_total = loss_asv + loss_adv + loss_recon + lambda_FM*loss_FM   \n",
    "#             # optm G\n",
    "#             self.gen.zero_grad()\n",
    "#             loss_recon.backward()\n",
    "#             self.g_opt.step()      \n",
    "        \n",
    "            # viusalizations     \n",
    "            index += len(label)\n",
    "            top1 += acc\n",
    "            # top2 += acc2\n",
    "            spk_loss += cls_loss.detach().cpu().numpy()\n",
    "            # estimation_loss += pred_loss.detach().cpu().numpy()\n",
    "#             G_loss += loss_total.detach().cpu().numpy()\n",
    "#             D_loss += loss_D.detach().cpu().numpy()\n",
    "            \n",
    "            # %.nf 保留n位小数\n",
    "            sys.stderr.write(time.strftime(\"%m-%d %H:%M:%S\") + \\\n",
    "            \" [%2d] Lr: %5f, Training: %.2f%%, \"  %(epoch, lr, 100 * (num / train_loader.__len__())) + \\\n",
    "            # \" Spk_loss: %.5f, pred_loss: %.5f, ACC: %2.2f%%\\r\"     % (spk_loss/(num), estimation_loss/num, top1/index*len(label))) # + \\\n",
    "            \" Spk_loss: %.5f,  ACC: %2.2f%%\\r\"      % (spk_loss/(num), top1/index*len(label)))          \n",
    "            # \" pred_loss: %.5f, ACC2: %2.2f%%\\r\"  %(estimation_loss/num, top2/index*len(label))) # + \\ \n",
    "            # \"G_loss: %.5f, D_loss: %.5f\\r\"   %( G_loss/(num), D_loss/(num)))  # + \\ \n",
    "            sys.stderr.flush()\n",
    "            \n",
    "        sys.stdout.write(\"\\n\") \n",
    "        # return spk_loss/num, estimation_loss/num, G_loss/num, D_loss/num, lr, top1/index*len(label)\n",
    "        \n",
    "       \n",
    "    \n",
    "#     def eval_prediction_a(self, path, a):\n",
    "#         self.eval()\n",
    "#         file_list = os.listdir(path)\n",
    "#         mse_err = []\n",
    "#         with torch.no_grad():\n",
    "#             for file in file_list:\n",
    "#                 audio, sr = self.load_wav_to_torch(os.path.join(path, file))\n",
    "#                 mel = self.get_mel(audio).unsqueeze(0).cuda()\n",
    "#                 spk_emb = self.encoder(mel, task='ft_emb')\n",
    "#                 a = torch.tensor([a]).unsqueeze(0).cuda()\n",
    "#                 _, pred_alpha = self.ploss(spk_emb, a)\n",
    "#                 loss = F.l1_loss(pred_alpha, a)    \n",
    "#                 mse_err.append(loss)\n",
    "                \n",
    "#         return sum(mse_err)/len(file_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def eval_prediction(self, path, a):\n",
    "        self.eval()\n",
    "        file_list = os.listdir(path)\n",
    "        mse_err = []\n",
    "        with torch.no_grad():\n",
    "            for file in file_list:\n",
    "                try:\n",
    "                    audio, sr = self.load_wav_to_torch(os.path.join(path, file))\n",
    "                    mel = self.get_mel(audio).unsqueeze(0).cuda()\n",
    "                    spk_emb = self.encoder(mel, task='ft_emb')\n",
    "                \n",
    "                    if len(file.split('_'))>1:\n",
    "                        a = torch.tensor([float(file.split('_')[1])]).unsqueeze(0).cuda()\n",
    "                        _, pred_alpha = self.ploss(spk_emb, a)\n",
    "                    else:\n",
    "                        a = torch.tensor([a]).unsqueeze(0).cuda()\n",
    "                        _, pred_alpha = self.ploss(spk_emb, a)\n",
    "                    \n",
    "                    loss = F.l1_loss(pred_alpha, a)    \n",
    "                    mse_err.append(loss)\n",
    "                    \n",
    "                except:\n",
    "                    print(file)\n",
    "        \n",
    "        \n",
    "        if len(file_list)>0:\n",
    "            return sum(mse_err)/len(file_list)\n",
    "        \n",
    "        else:\n",
    "            print(path)\n",
    "            \n",
    "            \n",
    "    def eval_network(self, eval_list, eval_path):\n",
    "        self.eval()\n",
    "        files = []\n",
    "        embeddings = {}\n",
    "        lines = open(eval_list).read().splitlines()\n",
    "        for line in lines:\n",
    "            files.append(line.split()[1])\n",
    "            files.append(line.split()[2])\n",
    "        setfiles = list(set(files))\n",
    "        setfiles.sort()\n",
    "\n",
    "        for idx, file in tqdm.tqdm(enumerate(setfiles), total = len(setfiles)):\n",
    "            audio, _  = self.load_wav_to_torch(os.path.join(eval_path, file))\n",
    "            # Full utterance\n",
    "            # data_1 = torch.FloatTensor(numpy.stack([audio],axis=0)).cuda()\n",
    "            mel_1 = self.get_mel(audio).unsqueeze(0).cuda()\n",
    "            # Spliited utterance matrix\n",
    "            # max_audio = 300 * 160 + 240\n",
    "            # if audio.shape[0] <= max_audio:\n",
    "            #     shortage = max_audio - audio.shape[0]\n",
    "            #     audio = numpy.pad(audio, (0, shortage), 'wrap')\n",
    "            # feats = []\n",
    "            # startframe = numpy.linspace(0, audio.shape[0]-max_audio, num=5)\n",
    "            # for asf in startframe:\n",
    "            #     feats.append(audio[int(asf):int(asf)+max_audio])\n",
    "            # feats = numpy.stack(feats, axis = 0).astype(numpy.float)\n",
    "            # # data_2 = torch.FloatTensor(feats).cuda()\n",
    "            # mel_2 = self.get_mel(feats).unsqueeze(0).cuda()\n",
    "            # Speaker embeddings\n",
    "            with torch.no_grad():\n",
    "                embedding_1 = self.encoder.forward(mel_1, task='ft_emb')\n",
    "                embedding_1 = F.normalize(embedding_1, p=2, dim=1)\n",
    "                embedding_2 = self.encoder.forward(mel_1, task='ft_emb')\n",
    "                embedding_2 = F.normalize(embedding_2, p=2, dim=1)\n",
    "            embeddings[file] = [embedding_1, embedding_2]\n",
    "        scores, labels  = [], []\n",
    "\n",
    "        for line in lines:\n",
    "            embedding_11, embedding_12 = embeddings[line.split()[1]]\n",
    "            embedding_21, embedding_22 = embeddings[line.split()[2]]\n",
    "            # Compute the scores\n",
    "            score_1 = torch.mean(torch.matmul(embedding_11, embedding_21.T)) # higher is positive\n",
    "            score_2 = torch.mean(torch.matmul(embedding_12, embedding_22.T))\n",
    "            score = (score_1 + score_2) / 2\n",
    "            score = score.detach().cpu().numpy()\n",
    "            scores.append(score)\n",
    "            labels.append(int(line.split()[0]))\n",
    "\n",
    "        # Coumpute EER and minDCF\n",
    "        EER = tuneThresholdfromScore(scores, labels, [1, 0.1])[1]\n",
    "        fnrs, fprs, thresholds = ComputeErrorRates(scores, labels)\n",
    "        minDCF, _ = ComputeMinDcf(fnrs, fprs, thresholds, 0.05, 1, 1)\n",
    "\n",
    "        return EER, minDCF\n",
    "\n",
    "    \n",
    "    \n",
    "#     def eval_network(self, test_loader): \n",
    "#         self.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for i, (fbank_s, _, label, a) in enumerate(test_loader):\n",
    "#                 num = i+1\n",
    "#                 fbank_s = fbank_s.cuda()\n",
    "#                 label   = label.cuda()\n",
    "#                 a       = a.unsqueeze(-1).cuda()\n",
    "\n",
    "#                 spk_emb = self.encoder(fbank_s, task='ft_emb')\n",
    "#                 cls_loss, acc = self.closs(spk_emb, a, label)      \n",
    "#                 pred_loss, _ = self.ploss(spk_emb.detach(), a, mode='eval')         \n",
    "\n",
    "#                 index += len(label)\n",
    "#                 top1 += acc\n",
    "#                 spk_loss += cls_loss.detach().cpu().numpy()\n",
    "#                 estimation_loss += pred_loss.detach().cpu().numpy()\n",
    "                \n",
    "#                 sys.stderr.write(time.strftime(\"%m-%d %H:%M:%S\") + \\\n",
    "#                 \" [%2d] Lr: %5f, Training: %.2f%%, \"  %(epoch, lr, 100 * (num / train_loader.__len__())) + \\\n",
    "#                 \" Spk_loss: %.5f, pred_loss: %.5f, ACC: %2.2f%%\\r\"     % (spk_loss/(num), estimation_loss/num, top1/index*len(label))) # + \\     \n",
    "            \n",
    "#                 sys.stderr.flush()       \n",
    "#             sys.stdout.write(\"\\n\") \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2117432-a889-4073-9e43-8e78f18367f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now load a SSL pretrained models from save_model/SSAST-Base-Frame-400.pth\n",
      "pretraining patch split stride: frequency=128, time=2\n",
      "pretraining patch shape: frequency=128, time=2\n",
      "pretraining patch array dimension: frequency=1, time=512\n",
      "pretraining number of patches=512\n",
      "fine-tuning patch split stride: frequncey=128, time=1\n",
      "fine-tuning number of patches=499\n"
     ]
    }
   ],
   "source": [
    "framework = ASVframework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b1850f-212f-416f-ab62-a57da1392b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "framework.load_parameters('save_model/model_Vox1_k128_damsoft0030.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c28f60-9721-42a4-ad08-42c636e33e06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4556/4556 [47:29<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "EER, minDCF = framework.eval_network('Dataset/filelist_Vox1_test.txt', '/root/autodl-tmp/vox1_test/wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e673b67-d5a6-47ec-a0e3-4dbf58985bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.8359454508447"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f10efec1-3974-4509-9f71-487c2baeb87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8783329940972939"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a83eac-bc17-4f32-be93-665c203942dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-03 22:59:46 [ 0] Lr: 0.000100, Training: 100.00%,  Spk_loss: 36.75592,  ACC: 1.36%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 00:36:19 [ 1] Lr: 0.000100, Training: 100.00%,  Spk_loss: 29.57802,  ACC: 9.75%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 02:12:32 [ 2] Lr: 0.000100, Training: 100.00%,  Spk_loss: 21.78222,  ACC: 23.45%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 03:48:32 [ 3] Lr: 0.000100, Training: 100.00%,  Spk_loss: 15.47819,  ACC: 39.02%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 05:25:16 [ 4] Lr: 0.000100, Training: 100.00%,  Spk_loss: 11.00468,  ACC: 52.96%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 07:02:15 [ 5] Lr: 0.000100, Training: 100.00%,  Spk_loss: 7.89179,  ACC: 63.99%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 08:38:19 [ 6] Lr: 0.000100, Training: 100.00%,  Spk_loss: 5.75701,  ACC: 72.18%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 10:14:17 [ 7] Lr: 0.000100, Training: 100.00%,  Spk_loss: 4.27659,  ACC: 78.18%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 11:45:28 [ 8] Lr: 0.000100, Training: 100.00%,  Spk_loss: 3.27719,  ACC: 82.40%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 13:13:51 [ 9] Lr: 0.000100, Training: 100.00%,  Spk_loss: 2.54629,  ACC: 85.68%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 14:42:08 [10] Lr: 0.000100, Training: 100.00%,  Spk_loss: 2.06091,  ACC: 87.94%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 16:00:19 [11] Lr: 0.000100, Training: 100.00%,  Spk_loss: 1.69758,  ACC: 89.71%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 17:21:08 [12] Lr: 0.000100, Training: 100.00%,  Spk_loss: 1.42103,  ACC: 91.06%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 18:41:27 [13] Lr: 0.000100, Training: 100.00%,  Spk_loss: 1.21485,  ACC: 92.09%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 20:02:03 [14] Lr: 0.000100, Training: 100.00%,  Spk_loss: 1.05968,  ACC: 92.85%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 21:22:11 [15] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.91572,  ACC: 93.69%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 22:42:20 [16] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.81393,  ACC: 94.20%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-04 23:57:54 [17] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.72627,  ACC: 94.65%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 01:17:48 [18] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.65320,  ACC: 95.02%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 02:36:52 [19] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.58648,  ACC: 95.44%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 03:56:57 [20] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.53774,  ACC: 95.71%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 05:16:50 [21] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.49248,  ACC: 95.95%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 05:37:15 [22] Lr: 0.000100, Training: 25.41%,  Spk_loss: 0.46330,  ACC: 96.18%\r"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # i = 0\n",
    "    framework.train_network(i, train_loader)\n",
    "    if i % 3 == 0:\n",
    "        framework.save_parameters('save_model' + \"/model_Vox1_k128_damsoft%04d.model\"%(i+21))\n",
    "    \n",
    "    # i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47babc4-bd83-4dd8-8d45-779e2ef04cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 09:02:15 [ 0] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.44813,  ACC: 96.22%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 10:22:28 [ 1] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.40733,  ACC: 96.48%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 11:43:24 [ 2] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.38142,  ACC: 96.69%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 13:04:03 [ 3] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.35788,  ACC: 96.87%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 14:23:06 [ 4] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.33918,  ACC: 97.04%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 15:37:45 [ 5] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.30923,  ACC: 97.30%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 16:52:25 [ 6] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.29039,  ACC: 97.43%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 18:07:25 [ 7] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.27598,  ACC: 97.56%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 19:17:52 [ 8] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.26592,  ACC: 97.65%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 20:27:10 [ 9] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.26302,  ACC: 97.71%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-05 20:41:07 [10] Lr: 0.000100, Training: 19.79%,  Spk_loss: 0.26099,  ACC: 97.73%\r"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # i = 0\n",
    "    framework.train_network(i, train_loader)\n",
    "    if i % 3 == 0:\n",
    "        framework.save_parameters('save_model' + \"/model_Vox1_k128_damsoft%04d.model\"%(i+21))\n",
    "    \n",
    "    # i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba656a-d705-434a-b229-968d0245fa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-18 23:18:03 [ 0] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.23555, pred_loss: 4.82882, ACC: 97.80%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-19 00:26:55 [ 1] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.23555, pred_loss: 3.93283, ACC: 97.80%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-19 01:33:31 [ 2] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.23555, pred_loss: 3.37557, ACC: 97.80%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-19 07:18:04 [ 7] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.23555, pred_loss: 2.10564, ACC: 97.80%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-19 08:26:17 [ 8] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.23555, pred_loss: 1.97830, ACC: 97.80%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-19 09:33:09 [ 9] Lr: 0.000100, Training: 99.86%,  Spk_loss: 0.23580, pred_loss: 1.86810, ACC: 97.79%\r"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # i = 0\n",
    "    framework.train_network(i, train_loader)\n",
    "    if i % 3 == 0:\n",
    "        framework.save_parameters('save_model' + \"/model_Vox1_k128_aamsoft_impact_ref%04d.model\"%(i))\n",
    "    \n",
    "    # i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb3084-5e30-4820-8205-87ce2f90297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac51e6e-60c3-4bf6-b0c2-531e5cde71dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-17 20:31:47 [ 0] Lr: 0.000100, Training: 100.00%,  Spk_loss: 36.70421, pred_loss: 0.66339, ACC: 1.09%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-17 21:38:46 [ 1] Lr: 0.000100, Training: 100.00%,  Spk_loss: 29.73396, pred_loss: 0.57681, ACC: 8.57%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-17 22:45:03 [ 2] Lr: 0.000100, Training: 100.00%,  Spk_loss: 21.86984, pred_loss: 0.59950, ACC: 21.87%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-17 23:51:26 [ 3] Lr: 0.000100, Training: 100.00%,  Spk_loss: 15.24692, pred_loss: 0.57982, ACC: 37.70%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-18 00:58:16 [ 4] Lr: 0.000100, Training: 100.00%,  Spk_loss: 10.47455, pred_loss: 0.56114, ACC: 52.32%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-18 02:06:19 [ 5] Lr: 0.000100, Training: 100.00%,  Spk_loss: 7.22164, pred_loss: 0.54357, ACC: 64.15%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-18 03:12:44 [ 6] Lr: 0.000100, Training: 100.00%,  Spk_loss: 5.07079, pred_loss: 0.52807, ACC: 72.88%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.0100, Training: 28.81%,  Spk_loss: 4.02351, pred_loss: 0.51706, ACC: 77.39%\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "12-18 07:39:47 [10] Lr: 0.000100, Training: 100.00%,  Spk_loss: 1.52531, pred_loss: 0.47363, ACC: 89.67%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-18 08:46:19 [11] Lr: 0.000100, Training: 100.00%,  Spk_loss: 1.21968, pred_loss: 0.46459, ACC: 91.40%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-18 09:52:48 [12] Lr: 0.000100, Training: 100.00%,  Spk_loss: 1.00200, pred_loss: 0.45941, ACC: 92.67%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-18 10:59:07 [13] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.85502, pred_loss: 0.45211, ACC: 93.61%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-18 12:05:39 [14] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.74324, pred_loss: 0.44568, ACC: 94.26%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-18 13:12:17 [15] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.65091, pred_loss: 0.44202, ACC: 94.90%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-18 13:39:32 [16] Lr: 0.000100, Training: 41.05%,  Spk_loss: 0.59690, pred_loss: 0.43926, ACC: 95.27%\r"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # i = 0\n",
    "    framework.train_network(i, train_loader)\n",
    "    if i % 3 == 0:\n",
    "        framework.save_parameters('save_model' + \"/model_Vox1_k128_jft_aamsoft%04d.model\"%(i))\n",
    "    \n",
    "    # i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc8f67-3747-43de-a761-cb6789392fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241c504-8cb9-4866-b01a-1464b7c36c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-17 18:21:34 [ 0] Lr: 0.000100, Training: 100.00%,  Spk_loss: 14.16132, pred_loss: 0.29113, ACC: 2.85%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-17 19:22:11 [ 1] Lr: 0.000100, Training: 91.16%,  Spk_loss: 6.78183, pred_loss: 0.12628, ACC: 9.20%\r"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # i = 0\n",
    "    framework.train_network(i, train_loader)\n",
    "    if i % 3 == 0:\n",
    "        framework.save_parameters('save_model' + \"/model_Vox1_k128_jft_aamsoft%04d.model\"%(i))\n",
    "    \n",
    "    # i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7c06d-1147-48e1-8976-8cc78247eabd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-13 23:50:44 [ 0] Lr: 0.000100, Training: 100.00%,  Spk_loss: 35.90853, ACC: 1.75%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 00:57:51 [ 1] Lr: 0.000100, Training: 100.00%,  Spk_loss: 28.21510, ACC: 11.27%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 02:04:17 [ 2] Lr: 0.000100, Training: 100.00%,  Spk_loss: 20.47209, ACC: 25.51%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 03:10:49 [ 3] Lr: 0.000100, Training: 100.00%,  Spk_loss: 14.30644, ACC: 41.32%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 04:17:16 [ 4] Lr: 0.000100, Training: 100.00%,  Spk_loss: 9.91363, ACC: 55.42%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 05:23:40 [ 5] Lr: 0.000100, Training: 100.00%,  Spk_loss: 6.92692, ACC: 66.48%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 06:30:11 [ 6] Lr: 0.000100, Training: 100.00%,  Spk_loss: 4.94606, ACC: 74.47%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 07:36:29 [ 7] Lr: 0.000100, Training: 100.00%,  Spk_loss: 3.62408, ACC: 80.20%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 08:42:48 [ 8] Lr: 0.000100, Training: 100.00%,  Spk_loss: 2.76512, ACC: 84.13%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 09:49:13 [ 9] Lr: 0.000100, Training: 100.00%,  Spk_loss: 2.14160, ACC: 87.14%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 10:55:29 [10] Lr: 0.000100, Training: 100.00%,  Spk_loss: 1.71462, ACC: 89.24%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 12:01:47 [11] Lr: 0.000100, Training: 100.00%,  Spk_loss: 1.42189, ACC: 90.68%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 12:01:59 [12] Lr: 0.000100, Training: 0.15%,  Spk_loss: 1.38264, ACC: 91.32%\r"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # i = 0\n",
    "    framework.train_network(i, train_loader)\n",
    "    if i % 3 == 0:\n",
    "        framework.save_parameters('save_model' + \"/model_Vox1_k128_aamsoft%04d.model\"%(i))\n",
    "    \n",
    "    # i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48aca3e-cec9-4891-b718-7b9a02ea9b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 22:28:51 [ 0] Lr: 0.000100, Training: 100.00%,  Spk_loss: 1.01007, ACC: 92.88%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-14 23:36:16 [ 1] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.87538, ACC: 93.55%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 00:43:27 [ 2] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.76428, ACC: 94.20%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 01:49:45 [ 3] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.65908, ACC: 94.81%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 02:56:11 [ 4] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.59127, ACC: 95.20%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 04:03:00 [ 5] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.50913, ACC: 95.68%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 05:09:33 [ 6] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.46425, ACC: 95.88%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 06:15:48 [ 7] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.41565, ACC: 96.19%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 07:22:41 [ 8] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.37885, ACC: 96.47%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 08:29:31 [ 9] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.34227, ACC: 96.73%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 09:35:52 [10] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.31826, ACC: 96.93%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 10:42:07 [11] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.28970, ACC: 97.23%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 11:49:03 [12] Lr: 0.000100, Training: 100.00%,  Spk_loss: 0.28362, ACC: 97.32%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 11:49:26 [13] Lr: 0.000100, Training: 0.44%,  Spk_loss: 0.29220, ACC: 97.40%\r"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # i = 0\n",
    "    framework.train_network(i, train_loader)\n",
    "    if i % 4 == 0:\n",
    "        framework.save_parameters('save_model' + \"/model_Vox1_k128_aamsoft%04d.model\"%(i))\n",
    "    \n",
    "    # i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b347848-3759-4d9f-9f34-dc92936ac244",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 18:10:55 [ 0] Lr: 0.000100, Training: 100.00%,  pred_loss: 3.89200, ACC: 97.80%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 19:17:32 [ 1] Lr: 0.000100, Training: 100.00%,  pred_loss: 3.07436, ACC: 97.80%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 20:24:06 [ 2] Lr: 0.000100, Training: 100.00%,  pred_loss: 2.77466, ACC: 97.80%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-15 20:38:04 [ 3] Lr: 0.000100, Training: 20.15%,  pred_loss: 2.62424, ACC: 97.40%\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# opt pred\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# i = 0\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mframework\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m         framework\u001b[38;5;241m.\u001b[39msave_parameters(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_model\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/model_Vox1_k128_aamsoft\u001b[39m\u001b[38;5;132;01m%04d\u001b[39;00m\u001b[38;5;124m.model\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(i))\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mASVframework.train_network\u001b[0;34m(self, epoch, train_loader)\u001b[0m\n\u001b[1;32m    116\u001b[0m index, top1, spk_loss, estimation_loss, \\\n\u001b[1;32m    117\u001b[0m G_loss, D_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    118\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masv_opt\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]        \n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (fbank_s, fbank_o, label, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    121\u001b[0m     num \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    122\u001b[0m     fbank_s \u001b[38;5;241m=\u001b[39m fbank_s\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# opt pred\n",
    "for i in range(100):\n",
    "    # i = 0\n",
    "    framework.train_network(i, train_loader)\n",
    "    if i % 4 == 0:\n",
    "        framework.save_parameters('save_model' + \"/model_Vox1_k128_aamsoft%04d.model\"%(i))\n",
    "    \n",
    "    # i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd143f5-fca7-4eac-a6ef-29a2e25aebd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### DAMSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "f4960e78-2650-412e-a0f0-1754dadf9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 64\n",
    "m = 0.5\n",
    "c = 2\n",
    "k = 17\n",
    "eps = 1e-6\n",
    "in_features = 768\n",
    "out_features = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "6beffee8-2ae9-418e-a83b-1d55d05e1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = nn.Parameter(torch.FloatTensor(k, in_features, out_features))\n",
    "nn.init.xavier_uniform_(weight)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "factor = torch.tensor([8.1, 3.9, -8.1]).float().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "326277fa-6321-4923-947e-941aa2cad963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func_a = (m - 0.1*torch.pow(c, (factor/12)))\n",
    "func_a = m\n",
    "threshold = math.pi - func_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e0843bb1-d6ae-4e10-9d9a-0b2231b24a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b26690cd-1f59-406a-9ecc-07abf9dec447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.791592653589793"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6bd508df-d82e-449f-94c1-9a571b5a2787",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn([3, 768]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c930e3f3-9d57-4b56-bfac-6a92bfb49242",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.empty(3, dtype = torch.long).random_(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "da3c8453-00ec-4c8a-970f-4403df1357b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([45, 60, 46])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "06ccd226-c89c-46c0-bbd1-716dc6ed04cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_theta = torch.bmm(\n",
    "            F.normalize(inputs).unsqueeze(0).expand(k, *inputs.shape),  # k*b*f\n",
    "            F.normalize(weight, dim=1),  # normalize in_features dim   # k*f*c\n",
    "        )  # k*b*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "55cf3152-86cc-48fb-971e-026a67c2ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_theta = torch.max(cos_theta, dim=0)[0]  # b*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d030ff76-5e58-43d9-afcf-c4d77a366d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0897, 0.0811, 0.0832,  ..., 0.0789, 0.1000, 0.0571],\n",
       "        [0.0481, 0.0675, 0.0630,  ..., 0.0747, 0.0484, 0.0512],\n",
       "        [0.1124, 0.1120, 0.0558,  ..., 0.0740, 0.1463, 0.0433]],\n",
       "       grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "3581d2a0-b5e4-44cb-89cf-c897dbf3b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.acos(torch.clamp(cos_theta, -1.0 + eps, 1.0 - eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "74f6dfec-3761-4476-9b60-0127efbe022b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4809, 1.4896, 1.4875,  ..., 1.4918, 1.4706, 1.5137],\n",
       "        [1.5227, 1.5032, 1.5078,  ..., 1.4960, 1.5223, 1.5195],\n",
       "        [1.4582, 1.4586, 1.5150,  ..., 1.4967, 1.4240, 1.5274]],\n",
       "       grad_fn=<AcosBackward0>)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "713f5195-b74c-4f14-b8f0-08f14c558595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = torch.zeros_like(cos_theta)\n",
    "one_hot.scatter_(1, label.unsqueeze(0).T.long(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6b09e0bf-a3dc-4e4f-b2b9-65923952f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = torch.where(theta > threshold, torch.zeros_like(one_hot), one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ce6098c9-a490-4be0-8e82-2692abcdde47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "03237fa7-681c-49b1-a12b-95f01d94f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.cos(torch.where(selected.bool(), theta + func_a, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "6d6af247-c6d8-4412-96fd-92ac7674d058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0897, 0.0811, 0.0832,  ..., 0.0789, 0.1000, 0.0571],\n",
       "        [0.0481, 0.0675, 0.0630,  ..., 0.0747, 0.0484, 0.0512],\n",
       "        [0.1124, 0.1120, 0.0558,  ..., 0.0740, 0.1463, 0.0433]],\n",
       "       grad_fn=<CosBackward0>)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "1bc1d4ed-89f1-4945-8b28-995176966e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits *= s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9344c2ad-6461-473a-8744-98bef8ef93d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-17.4749, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9953b791-96ca-4fca-bf8f-a7b7c6126d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = loss_fn(logits, label)\n",
    "        \n",
    "# prec1 = accuracy(logits.detach(), label.detach(), topk=(1,))[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e328a5df-c820-4e97-b608-43a00c7ac439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46.8266, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb97fd-9a3b-40e8-a9e8-ba5fcdf7b5c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "41ea88e9-5786-41c6-a18d-3fe74226b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio1, sr1 = framework.load_wav_to_torch('/root/autodl-tmp/Dataset/ASV/Vox1/train_scaled/id10044/tEiC2TFawPM/00006.wav')\n",
    "audio2, sr2 = framework.load_wav_to_torch('/root/autodl-tmp/Dataset/ASV/Vox1/train_scaled/id10044/tEiC2TFawPM/00005_11.591_.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4bef17bd-0c58-4085-a409-858aae368a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel1 = framework.get_mel(audio1).unsqueeze(0).cuda()\n",
    "mel2 = framework.get_mel(audio2).unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8cdc5f61-f04a-41a0-94c9-4383c1958506",
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_emb1 = framework.encoder(mel1, task='ft_emb')\n",
    "spk_emb2 = framework.encoder(mel2, task='ft_emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "52bd1da9-6f6e-4b96-9c19-617df01b6a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "simi = nn.CosineSimilarity(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "649a13ca-8d4b-487f-aaca-5a73ec0a87da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = simi(spk_emb1, spk_emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ff577887-866b-428f-a22c-f07dd764f15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0779], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7815ae32-921a-4678-92dc-f839ba34a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = torch.tensor([-11.512]).float().unsqueeze(0).cuda()\n",
    "a2 = torch.tensor([0.0]).float().unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bb0c46b-afbd-4e6d-8ee3-7079f7530e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_loss1, pred_a1 = framework.ploss(spk_emb1, a1)     \n",
    "pred_loss2, pred_a2 = framework.ploss(spk_emb2, a2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0811d097-d053-472f-8752-165b4fb072ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6396, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor([[-9.3724]], device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pred_loss1, pred_a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce535a9-2640-4a85-b6d6-c341fce671d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1937, device='cuda:0', grad_fn=<SmoothL1LossBackward0>) tensor([[3.6937]], device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pred_loss2, pred_a2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ba13d170-da3b-4f3f-b626-d08272f49536",
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_id1=torch.tensor([44]).long().cuda()\n",
    "spk_id2=torch.tensor([44]).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9cab4b99-ef0e-4f3a-a6bf-04a6acf5249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "closs1, acc1, logit1 = framework.closs(spk_emb1, spk_id1)\n",
    "theta_n1 = framework.closs.forward_(spk_emb1)\n",
    "closs2, acc2, logit2 = framework.closs(spk_emb2, spk_id2)\n",
    "theta_n2 = framework.closs.forward_(spk_emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ae1a361-2d50-426e-9bd4-b5fd4a2f1a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100.], device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abf244dd-4e8c-4e26-8de2-f45c962c576e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.4253], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit1[:,27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02f25426-8ad4-45b4-8cef-7583859bd6df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1842], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_n1[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81fc0c95-09ea-4d18-98e2-85d45173ecc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1029], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_n2[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b95ce71b-075d-47fc-91a9-d2fd5658f68c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([38.4305], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit[:,38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7410705b-c631-4f2a-89ae-33c0eb0860c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = F.softmax(logit, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41c2c015-fcdc-489d-95cc-cb37678ed422",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[:, 38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28b41c7f-d931-4495-a790-7d261adc22bf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1277, -0.2082, -0.1075, -0.1524, -0.1981, -1.1253, -0.1961, -0.1244,\n",
       "         -0.1468, -0.1429, -0.2088, -0.2758, -0.2269, -0.1990, -0.2318, -0.1773,\n",
       "         -0.2411, -0.1388, -0.1311, -0.1614, -0.1783, -0.1951, -0.1518, -0.1650,\n",
       "         -0.1961, -0.1863, -0.1781, -0.2543, -0.1587, -0.1361, -0.1094, -0.1182,\n",
       "         -0.2540, -0.2285, -0.1894, -0.1634, -0.1488, -0.2225, -0.2157, -0.2639,\n",
       "         -0.1566, -0.1488, -0.1758, -0.1054, -0.2924, -0.2266, -0.3419, -0.1714,\n",
       "         -0.2621, -0.1709, -0.2408, -0.1810, -0.1785, -0.1999, -0.1231, -0.2149,\n",
       "         -0.1401, -0.1771, -0.1794, -0.2929, -0.1307, -0.1406, -0.1548, -0.2056,\n",
       "         -0.1716, -0.1192, -0.1645, -0.1361, -0.1850, -0.1706, -0.1471, -0.2651,\n",
       "         -0.1673, -0.1561, -0.2333, -0.1830, -0.2413, -0.1460, -0.1618, -0.1394,\n",
       "         -0.2380, -0.2417, -0.1471, -0.2011, -0.3049, -0.2327, -0.1736, -0.1780,\n",
       "         -0.2123, -0.1151, -0.1630, -0.1581, -0.1308, -0.2459, -0.2080, -0.2723,\n",
       "         -0.1845, -0.1451, -0.2359, -0.2434, -0.1173, -0.2224, -0.1523, -0.1812,\n",
       "         -0.1866, -0.1656, -0.1806, -0.2223, -0.2433, -0.2595, -0.1623, -0.1657,\n",
       "         -0.2620, -0.2597, -0.1434, -0.1129, -0.1644, -0.1357, -0.3245, -0.2421,\n",
       "         -0.2428, -0.2038, -0.2215, -0.1906, -0.2152, -0.1348, -0.1665, -0.2488,\n",
       "         -0.1947, -0.1330, -0.1740, -0.1495, -0.1585, -0.1906, -0.1532, -0.2137,\n",
       "         -0.2194, -0.1500, -0.1652, -0.2105, -0.1573, -0.1396, -0.2433, -0.1186,\n",
       "         -0.2655, -0.1421, -0.2224, -0.1975, -0.2162, -0.1076, -0.1750, -0.1789,\n",
       "         -0.2173, -0.1150, -0.1386, -0.2135, -0.1336, -0.1967, -0.2040, -0.2073,\n",
       "         -0.1405, -0.1469, -0.1191, -0.1582, -0.1213, -0.1267, -0.1323, -0.1021,\n",
       "         -0.1860, -0.2297, -0.2221, -0.1394, -0.1346, -0.1933, -0.2257, -0.1596,\n",
       "         -0.2388, -0.1442, -0.1930, -0.1551, -0.1354, -0.1728, -0.1676, -0.1927,\n",
       "         -0.2006, -0.1631, -0.1516, -0.2100, -0.1317, -0.1524, -0.1794, -0.1758,\n",
       "         -0.1546, -0.1439, -0.1920, -0.1948, -0.1099, -0.2092, -0.2434, -0.2129,\n",
       "         -0.3221, -0.1625, -0.1775, -0.2397, -0.1734, -0.1547, -0.1072, -0.1526,\n",
       "         -0.1518, -0.1282, -0.0929, -0.2264, -0.1401, -0.1698, -0.1718, -0.1733,\n",
       "         -0.2116, -0.1604, -0.1720, -0.2809, -0.2795, -0.1937, -0.1845, -0.1325,\n",
       "         -0.1938, -0.1659, -0.2747, -0.1617, -0.1663, -0.1562, -0.2777, -0.1684,\n",
       "         -0.2113, -0.2524, -0.1590, -0.1453, -0.1738, -0.1932, -0.1311, -0.1753,\n",
       "         -0.1856, -0.1876, -0.2048, -0.1354, -0.1313, -0.1239, -0.1207, -0.1484,\n",
       "         -0.1737, -0.1610, -0.2459, -0.1838, -0.1663, -0.1832, -0.2159, -0.1399,\n",
       "         -0.1853, -0.1989, -0.1303, -0.2079, -0.1396, -0.1819, -0.1299, -0.2292,\n",
       "         -0.1109, -0.1382, -0.1541, -0.1708, -0.2010, -0.1416, -0.2532, -0.0933,\n",
       "         -0.1989, -0.1736, -0.1766, -0.1677, -0.2572, -0.2307, -0.1016, -0.2213,\n",
       "         -0.2216, -0.3189, -0.2094, -0.1789, -0.1747, -0.1172, -0.1734, -0.1730,\n",
       "         -0.1451, -0.2076, -0.1720, -0.1426, -0.1609, -0.1862, -0.1536, -0.2416,\n",
       "         -0.2430, -0.1580, -0.2131, -0.2673, -0.0857, -0.1473, -0.1240, -0.1747,\n",
       "         -0.1535, -0.1551, -0.1743, -0.1961, -0.1875, -0.1868, -0.1798, -0.1422,\n",
       "         -0.2178, -0.1358, -0.2631, -0.1556, -0.1620, -0.2228, -0.1128, -0.2002,\n",
       "         -0.1309, -0.1294, -0.1369, -0.1415, -0.1144, -0.2052, -0.1643, -0.1360,\n",
       "         -0.1624, -0.1620, -0.1363, -0.1210, -0.1936, -0.2122, -0.0774, -0.2519,\n",
       "         -0.1196, -0.2205, -0.1952, -0.2014, -0.1922, -0.1456, -0.2514, -0.2405,\n",
       "         -0.1141, -0.1631, -0.2863, -0.1178, -0.2595, -0.1758, -0.2903, -0.1287,\n",
       "         -0.1360, -0.1785, -0.1761, -0.1705, -0.1329, -0.2013, -0.2815, -0.2492,\n",
       "         -0.1560, -0.2194, -0.1380, -0.1148, -0.2011, -0.1940, -0.1225, -0.1994,\n",
       "         -0.2094, -0.2193, -0.2119, -0.1777, -0.1635, -0.1846, -0.1239, -0.2140,\n",
       "         -0.1507, -0.1392, -0.1623, -0.1671, -0.1932, -0.2731, -0.1733, -0.2003,\n",
       "         -0.1721, -0.1913, -0.1444, -0.1727, -0.1483, -0.2302, -0.1953, -0.1840,\n",
       "         -0.1799, -0.2478, -0.2062, -0.1744, -0.2070, -0.1793, -0.1958, -0.1722,\n",
       "         -0.1572, -0.2320, -0.1579, -0.2108, -0.2070, -0.1522, -0.1194, -0.1340,\n",
       "         -0.2096, -0.2725, -0.1369, -0.1362, -0.1532, -0.1217, -0.1836, -0.2002,\n",
       "         -0.2230, -0.2056, -0.1943, -0.2566, -0.1375, -0.1838, -0.2066, -0.1497,\n",
       "         -0.1299, -0.2527, -0.3048, -0.1741, -0.1279, -0.1804, -0.1312, -0.1581,\n",
       "         -0.2012, -0.1919, -0.1474, -0.2329, -0.2919, -0.2171, -0.1383, -0.2042,\n",
       "         -0.1505, -0.1555, -0.2936, -0.1866, -0.1913, -0.1311, -0.1890, -0.3234,\n",
       "         -0.2216, -0.2221, -0.3099, -0.2544, -0.2327, -0.1137, -0.1698, -0.2200,\n",
       "         -0.1953, -0.3323, -0.1933, -0.1871, -0.2331, -0.1796, -0.1705, -0.1471,\n",
       "         -0.2645, -0.2766, -0.1521, -0.1402, -0.2176, -0.1858, -0.1959, -0.1654,\n",
       "         -0.1952, -0.2248, -0.2340, -0.1239, -0.1553, -0.2020, -0.2060, -0.2958,\n",
       "         -0.0972, -0.2189, -0.1777, -0.1247, -0.1961, -0.2270, -0.1646, -0.2759,\n",
       "         -0.1800, -0.1388, -0.2130, -0.2166, -0.1779, -0.1441, -0.1636, -0.1860,\n",
       "         -0.0878, -0.1568, -0.1338, -0.1822, -0.1228, -0.0906, -0.1470, -0.1837,\n",
       "         -0.2230, -0.2053, -0.2260, -0.1954, -0.2978, -0.2106, -0.1964, -0.2000,\n",
       "         -0.1732, -0.1707, -0.1711, -0.2140, -0.1947, -0.1341, -0.1060, -0.1339,\n",
       "         -0.1618, -0.1547, -0.2203, -0.2332, -0.2649, -0.1782, -0.1265, -0.1999,\n",
       "         -0.1664, -0.2079, -0.1549, -0.1663, -0.1505, -0.1583, -0.1103, -0.1331,\n",
       "         -0.1763, -0.1672, -0.1615, -0.2133, -0.1035, -0.1205, -0.1662, -0.2139,\n",
       "         -0.1385, -0.2548, -0.1760, -0.1791, -0.1539, -0.1102, -0.1590, -0.1485,\n",
       "         -0.1815, -0.1971, -0.2232, -0.1085, -0.1844, -0.1656, -0.1922, -0.1973,\n",
       "         -0.1846, -0.1436, -0.1943, -0.1383, -0.1696, -0.2218, -0.1579, -0.1701,\n",
       "         -0.1661, -0.1357, -0.1915, -0.2711, -0.2016, -0.1169, -0.1573, -0.1840,\n",
       "         -0.1274, -0.2554, -0.2568, -0.1457, -0.1617, -0.1761, -0.2055, -0.1619,\n",
       "         -0.1570, -0.1893, -0.1395, -0.1368, -0.2611, -0.2412, -0.2383, -0.1717,\n",
       "         -0.1805, -0.1960, -0.2650, -0.1732, -0.1194, -0.1460, -0.1087, -0.1607,\n",
       "         -0.1556, -0.1788, -0.2494, -0.1679, -0.1309, -0.1240, -0.2260, -0.1413,\n",
       "         -0.2497, -0.1289, -0.1798, -0.2674, -0.1086, -0.1399, -0.1000, -0.0870,\n",
       "         -0.1358, -0.1926, -0.1496, -0.1493, -0.1724, -0.1720, -0.1061, -0.1617,\n",
       "         -0.1955, -0.2261, -0.1955, -0.1973, -0.1935, -0.1835, -0.3076, -0.1863,\n",
       "         -0.2858, -0.0763, -0.2415, -0.1942, -0.1777, -0.1407, -0.2140, -0.1481,\n",
       "         -0.1406, -0.1469, -0.2132, -0.1417, -0.1726, -0.1611, -0.1867, -0.2449,\n",
       "         -0.2585, -0.2266, -0.1894, -0.2697, -0.1023, -0.1412, -0.1668, -0.1806,\n",
       "         -0.1486, -0.1860, -0.2256, -0.1412, -0.0960, -0.2393, -0.2851, -0.2215,\n",
       "         -0.1898, -0.2183, -0.1205, -0.1654, -0.2840, -0.2264, -0.2074, -0.1171,\n",
       "         -0.1648, -0.1613, -0.1465, -0.2007, -0.1749, -0.2018, -0.1841, -0.2293,\n",
       "         -0.2814, -0.1545, -0.1891, -0.1197, -0.1935, -0.1488, -0.1201, -0.1250,\n",
       "         -0.1779, -0.2191, -0.1913, -0.2136, -0.1904, -0.1842, -0.1244, -0.1552,\n",
       "         -0.1914, -0.2329, -0.1612, -0.1265, -0.2148, -0.2095, -0.1364, -0.1603,\n",
       "         -0.1848, -0.1623, -0.2083, -0.2388, -0.1882, -0.1507, -0.2167, -0.1934,\n",
       "         -0.1673, -0.1665, -0.1722, -0.1377, -0.1793, -0.2323, -0.1603, -0.1870,\n",
       "         -0.1693, -0.2336, -0.1662, -0.1208, -0.1793, -0.2504, -0.1946, -0.1386,\n",
       "         -0.2332, -0.1469, -0.2186, -0.2084, -0.1732, -0.1421, -0.2086, -0.1621,\n",
       "         -0.1573, -0.1538, -0.1864, -0.2146, -0.3181, -0.1428, -0.1691, -0.1736,\n",
       "         -0.1509, -0.2102, -0.1500, -0.2348, -0.2156, -0.1894, -0.1934, -0.1840,\n",
       "         -0.2469, -0.2154, -0.1819, -0.2860, -0.1676, -0.1879, -0.2108, -0.1444,\n",
       "         -0.0989, -0.2399, -0.0843, -0.0999, -0.0830, -0.1773, -0.1545, -0.1958,\n",
       "         -0.1519, -0.2548, -0.1026, -0.1919, -0.2182, -0.2680, -0.2204, -0.2731,\n",
       "         -0.1864, -0.2075, -0.1054, -0.1675, -0.2095, -0.1017, -0.1755, -0.1387,\n",
       "         -0.1542, -0.1154, -0.1560, -0.1692, -0.1625, -0.3187, -0.1498, -0.1979,\n",
       "         -0.1442, -0.2901, -0.2369, -0.1441, -0.2098, -0.1910, -0.2076, -0.2120,\n",
       "         -0.1326, -0.0836, -0.2891, -0.1399, -0.1403, -0.2005, -0.2089, -0.2263,\n",
       "         -0.2078, -0.1424, -0.1678, -0.1068, -0.1214, -0.2101, -0.1569, -0.2100,\n",
       "         -0.1582, -0.1661, -0.2082, -0.2992, -0.1018, -0.1762, -0.1972, -0.2094,\n",
       "         -0.1597, -0.1764, -0.2315, -0.2516, -0.1007, -0.0981, -0.2225, -0.1545,\n",
       "         -0.1842, -0.1666, -0.2453, -0.2540, -0.1041, -0.1114, -0.1477, -0.1765,\n",
       "         -0.2215, -0.1611, -0.2083, -0.1665, -0.1765, -0.1919, -0.1676, -0.1690,\n",
       "         -0.2487, -0.1815, -0.1594, -0.2568, -0.1504, -0.2792, -0.1048, -0.1713,\n",
       "         -0.2074, -0.2428, -0.2024, -0.1898, -0.1076, -0.1984, -0.1566, -0.1601,\n",
       "         -0.1443, -0.1244, -0.3021, -0.1899, -0.1366, -0.2150, -0.1653, -0.1546,\n",
       "         -0.1264, -0.1822, -0.1226, -0.1322, -0.1375, -0.2490, -0.2701, -0.1878,\n",
       "         -0.1919, -0.1598, -0.2780, -0.1257, -0.2390, -0.1906, -0.1656, -0.1237,\n",
       "         -0.1474, -0.1827, -0.1347, -0.1224, -0.2570, -0.0953, -0.2326, -0.2071,\n",
       "         -0.2071, -0.2059, -0.1701, -0.1026, -0.1756, -0.1587, -0.1611, -0.2047,\n",
       "         -0.1484, -0.2641, -0.1733, -0.1588, -0.1437, -0.1994, -0.3708, -0.1386,\n",
       "         -0.1644, -0.1471, -0.1421, -0.1313, -0.1559, -0.1867, -0.1590, -0.1581,\n",
       "         -0.1740, -0.1902, -0.1723, -0.2617, -0.1770, -0.1713, -0.2307, -0.1742,\n",
       "         -0.1593, -0.2045, -0.1448, -0.1085, -0.1032, -0.1316, -0.1329, -0.2345,\n",
       "         -0.1182, -0.1489, -0.1693, -0.1849, -0.1824, -0.1747, -0.2493, -0.1494,\n",
       "         -0.2182, -0.1631, -0.3297, -0.1549, -0.1571, -0.2721, -0.1698, -0.1940,\n",
       "         -0.1616, -0.2679, -0.1678, -0.1705, -0.2295, -0.2270, -0.2971, -0.1134,\n",
       "         -0.1470, -0.1827, -0.1618, -0.1984, -0.1783, -0.1717, -0.1596, -0.2528,\n",
       "         -0.1334, -0.1661, -0.0957, -0.2132, -0.1074, -0.1938, -0.1803, -0.1474,\n",
       "         -0.1707, -0.1612, -0.2170, -0.1446, -0.1846, -0.2007, -0.0778, -0.2618,\n",
       "         -0.1542, -0.1695, -0.1713, -0.1245, -0.1973, -0.1901, -0.1428, -0.1700,\n",
       "         -0.3495, -0.2062, -0.0856, -0.1783, -0.1714, -0.2310, -0.1858]],\n",
       "       device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d712b-b2bd-49f3-a9e9-ae072c1456e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = 'F:/datasets/project3/AISHELL-3/scaled'\n",
    "spk_list = os.listdir(filepath)\n",
    "loss = []\n",
    "for spk in spk_list:\n",
    "    pred_loss = framework.eval_prediction(os.path.join(filepath, spk), spk)\n",
    "    loss.append(pred_loss)\n",
    "\n",
    "loss = sum(loss)\n",
    "loss /= len(spk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762e3c7-ee87-49ff-a884-d0ff5e938ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd91b98-15a7-4e09-8061-16e0aa39e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f0a88-ec50-4d4f-b409-2a8aa691d75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2414, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(loss) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b4647-1236-438b-8018-16257770696f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_loss = framework.eval_prediction('F:/datasets/project3/AISHELL-1/unseen_scaled/S0736/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae6042-645d-4085-8622-69645c78bb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0710, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece3e93-c260-481c-8c14-d4f242f5344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'F:/datasets/project3/AISHELL-1/unseen_scaled/S0736/'\n",
    "\n",
    "def eval_prediction(path):\n",
    "    framework.eval()\n",
    "    file_list = os.listdir(path)\n",
    "    mse_err = []\n",
    "    for file in file_list:\n",
    "        audio, sr = framework.load_wav_to_torch(os.path.join(path, file))\n",
    "        mel = framework.get_mel(audio).unsqueeze(0).cuda()\n",
    "        spk_emb = framework.encoder(mel, task='ft_emb')\n",
    "        a = torch.tensor(float(file.split('_')[1])).cuda()\n",
    "        loss, pred_alpha = framework.ploss(spk_emb, a)\n",
    "        mse_err.append(pow(loss, 0.5))\n",
    "     \n",
    "    return sum(mse_err)/len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4be558-1ff4-413b-8c6b-67d3ee1a2ee3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\torch113\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.99 GiB total capacity; 22.55 GiB already allocated; 0 bytes free; 23.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43meval_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [7], line 10\u001b[0m, in \u001b[0;36meval_prediction\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      8\u001b[0m audio, sr \u001b[38;5;241m=\u001b[39m framework\u001b[38;5;241m.\u001b[39mload_wav_to_torch(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, file))\n\u001b[0;32m      9\u001b[0m mel \u001b[38;5;241m=\u001b[39m framework\u001b[38;5;241m.\u001b[39mget_mel(audio, sr)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m---> 10\u001b[0m spk_emb \u001b[38;5;241m=\u001b[39m \u001b[43mframework\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mft_emb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mfloat\u001b[39m(file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     12\u001b[0m loss, pred_alpha \u001b[38;5;241m=\u001b[39m framework\u001b[38;5;241m.\u001b[39mploss(spk_emb, a)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\torch113\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\my_pyfile\\pytorch\\DAMSoftmax\\model\\ast_model.py:480\u001b[0m, in \u001b[0;36mASTModel.forward\u001b[1;34m(self, x, task, cluster, mask_patch, x_vector)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinetuningcls(x)    \n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mft_emb\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinetuningemb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# pretraining, masked patch classification (discriminative objective)\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretrain_mpc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mE:\\my_pyfile\\pytorch\\DAMSoftmax\\model\\ast_model.py:308\u001b[0m, in \u001b[0;36mASTModel.finetuningemb\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    305\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv\u001b[38;5;241m.\u001b[39mpos_drop(x)\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk_id, blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[1;32m--> 308\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# x.shape = [B, 501, 768] 501个tokens(500 + 1 class token), 直接用class token做class embedding, 因为它汇聚了所有tokens上的信息\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# 注意vit的原理, 所有tokens本是一个序列信息, 选最前的一个class token就行, 即x[B, 0]\u001b[39;00m\n\u001b[0;32m    312\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\torch113\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\torch113\\lib\\site-packages\\timm\\models\\vision_transformer.py:199\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    198\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)))\n\u001b[1;32m--> 199\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\torch113\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\torch113\\lib\\site-packages\\timm\\models\\vision_transformer.py:148\u001b[0m, in \u001b[0;36mMlp.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    147\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n\u001b[1;32m--> 148\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(x)\n\u001b[0;32m    150\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\torch113\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\torch113\\lib\\site-packages\\torch\\nn\\modules\\activation.py:684\u001b[0m, in \u001b[0;36mGELU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 684\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapproximate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapproximate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.99 GiB total capacity; 22.55 GiB already allocated; 0 bytes free; 23.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "loss = eval_prediction(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055af01a-e456-4258-9b34-99a2a6c4feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sr = framework.load_wav_to_torch('F:/datasets/project3/AISHELL-1/unseen_scaled/S0736/BAC009S0736W0122_-6.952_.wav')\n",
    "mel = framework.get_mel(audio).unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37cd2c-d838-4751-b0e8-74db57a08222",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'BAC009S0736W0122_-6.952_.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b674df-179d-4336-8256-140353285a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(float(file.split('_')[1])).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bad35d-2409-419a-8dca-930d8a7e6f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.FloatTensor'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310eaf21-f5cf-4ad4-897b-81d384458709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.952"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(file.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c2e3c-f8aa-4b79-b758-e8148e9ab92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework.eval()\n",
    "spk_emb = framework.encoder(mel, task='ft_emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa8713-271c-4818-9c36-9443ec392699",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(-7).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e31699-0a62-4635-859d-b671d3a59e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7., device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc2126-73cc-4b52-96fc-2fef10ae6d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spk_id = framework.closs(spk_emb)\n",
    "loss, pred_alpha = framework.ploss(spk_emb, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b000f4-68fc-4437-9a45-e0e9ed442150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0955, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b55930-66be-4ef9-9e2a-7eba3d16d7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.3091]], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f6fcf1-7a1d-432b-8409-c5bbd53773a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework.save_parameters('save_model' + \"/model_%04d.model\"%13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086dbb3e-0c81-460b-b525-28401cf78905",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(1):\n",
    "\t## Training for one epoch\n",
    "\tloss, lr, acc = s.train_network(epoch = epoch, loader = trainLoader)\n",
    "\n",
    "\t## Evaluation every [test_step] epochs\n",
    "\tif epoch % args.test_step == 0:\n",
    "\t\ts.save_parameters(args.model_save_path + \"/model_%04d.model\"%epoch)\n",
    "\t\tEERs.append(s.eval_network(eval_list = args.eval_list, eval_path = args.eval_path)[0])\n",
    "\t\tprint(time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"%d epoch, ACC %2.2f%%, EER %2.2f%%, bestEER %2.2f%%\"%(epoch, acc, EERs[-1], min(EERs)))\n",
    "\t\tscore_file.write(\"%d epoch, LR %f, LOSS %f, ACC %2.2f%%, EER %2.2f%%, bestEER %2.2f%%\\n\"%(epoch, lr, loss, acc, EERs[-1], min(EERs)))\n",
    "\t\tscore_file.flush()\n",
    "\n",
    "\tif epoch >= args.max_epoch:\n",
    "\t\tquit()\n",
    "\n",
    "\tepoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b6516-51e8-480b-95a9-6111111da074",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=40\n",
    "lr=1e-04\n",
    "num=30\n",
    "top1=90\n",
    "index=30\n",
    "spk_loss=26\n",
    "estimation_loss=48\n",
    "G_loss=32\n",
    "D_loss=29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf2933-bb28-40c1-b46b-ae6a8e8fd254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-03 23:36:11 [40] Lr: 0.000100, Training: 0.40%,  Spk_loss: 0.86667, ACC: 96.00%,  pred_loss: 1.60000, G_loss: 1.06667, D_loss: 0.96667\r"
     ]
    }
   ],
   "source": [
    "sys.stderr.write(time.strftime(\"%m-%d %H:%M:%S\") + \\\n",
    "\" [%2d] Lr: %5f, Training: %.2f%%, \"    %(epoch, lr, 100 * (num / 7481)) + \\\n",
    "\" Spk_loss: %.5f, ACC: %2.2f%%, \"      %(spk_loss/(num), top1/index*32) + \\\n",
    "\" pred_loss: %.5f, G_loss: %.5f, D_loss: %.5f\\r\"   %(estimation_loss/num, G_loss/(num), D_loss/(num)))\n",
    "sys.stderr.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d244f3-3eee-4c2c-84ed-8d90f8efa241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
